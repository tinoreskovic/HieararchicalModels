---
title: "Hw9"
author: "Tin Oreskovic, Jade Le-Cascarino"
date: "2/15/2018"
output:
  pdf_document: 
    fig_caption: true
    keep_tex: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
hibbs <- read.csv("~/Desktop/hibbs.dat", sep="")
```

Following the insturctions at: http://www.stat.columbia.edu/~gelman/arm/Examples/Earnings/earnings_setup.R
```{r}
library(foreign)
earnings <- read.dta("~/Desktop/earnings.dta")
earnings$age <- 90 - earnings$yearbn # survey was conducted in 1990
earnings$age[earnings$age < 18] <- NA
earnings$age_category <- with(earnings, ifelse(age < 35, 1, ifelse(age < 50, 2, 3)))
earnings$eth <- with(earnings, ifelse(race==2, 1, ifelse(hisp==1, 2, ifelse(race==1, 3, 4))))
earnings$male <- 2 - earnings$sex
ok <- with(earnings, !is.na(earn + height + sex + age) & yearbn > 2)
earnings_clean <- earnings[ok,]
write.csv(earnings_clean, "earnings.csv")
```

```{r}
#install.packages('rstan', type = 'source', INSTALL_opts = "--merge-multiarch")
#install.packages("foreign")
#install.packages("ggplot2")
```

$\textbf{8.8.5 (a)}$

```{r}
library("rstanarm")
library("arm")
m2 <- stan_glm(inc.party.vote ~ growth, data=hibbs)
```

```{r}
print(m2)
```
Storing the matrix:
```{r}
sims <- as.matrix(m2)
n_sims <- nrow(sims)
a <- sims[,1]
b <- sims[,2]
sigma <- sims[,3]

```

Obtaining the point forecast and the s.e. of the predicted value: (52.33 and 4.04)
```{r}
y_hat <- a + 2.0*b 
y_pred <- rnorm(n_sims, y_hat, sigma)

Median <- median(y_pred)
MAD_SD <- mad(y_pred)
win_prob <- mean(y_pred > 50)
cat("Predicted Clinton percentage of 2-party vote: ", fround(Median, 2), ",
  with s.e. ", fround(MAD_SD, 2), "\nPr (Clinton win) = ", fround(win_prob, 2), sep="")
```

Now to obtain the s.e. of the linear predictor ('se_linpred,' 0.98):
```{r}
var(hibbs$growth)*(length(hibbs$growth)-1)/length(hibbs$growth)*16
mean(hibbs$growth)

se_linpred = median(sigma)*sqrt((1/16) + ((2 - 1.8975)^2)/29.2129)
fround(se_linpred, 2)

se_predict = median(sigma)*sqrt(1 + (1/16) + ((2 - 1.8975)^2)/29.2129)
fround(se_predict, 2)
```

$\textbf{8.8.5 (b)}$
(repeating the exercise with the prediction functions)
```{r}
new <- data.frame(growth=2.0)

linpred <- posterior_linpred(m2, newdata = new)

pred_value <- posterior_predict(m2, newdata = new)

median(linpred)
mad(linpred)

median(pred_value)
mad(pred_value)
```

\textbf{SHADOW TOPIC:}
see below for comparison with \textbf{b}

```{r}
hist(y_pred)
plot(a,b)
```


$\textbf{8.8.6 (a)}$


```{r}
library(ggplot2)
sqrt(var(earnings_clean$earn)*(length(earnings_clean$earn)-1)/length(earnings_clean$earn))
summary(earnings_clean$earn)
hist(earnings_clean$height)
hist(earnings_clean$earn)
ggplot(earnings_clean, aes(x=earnings_clean$height, y=log(earnings_clean$earn))) + geom_point()
```

```{r}
m3 <- stan_glm(earn ~ height, data=earnings_clean, prior = normal(1500, 1700, autoscale=FALSE))
```
(unfortunately, I can't seem to incorporate a log for earnings)
```{r}
print(m3)
```


Storing the matrix:
```{r}
sims2 <- as.matrix(m3)
n_sims2 <- nrow(sims2)
a2 <- sims2[,1]
b2 <- sims2[,2]
sigma2 <- sims2[,3]

```

Obtaining the point forecast and the s.e. of the predicted value: (17277 and 18860)
```{r}
y_hat2 <- a2 + 65*b2 
y_pred2 <- rnorm(n_sims2, y_hat2, sigma2)

Median2 <- median(y_pred2)
MAD_SD2 <- mad(y_pred2)
cat("Predicted Earnings of a 65-inch-tall person: ", fround(Median2, 2), ",
  with s.e. ", fround(MAD_SD2, 2))
```


Now to obtain the s.e. of the linear predictor ('se_linpred,' 552.13):
```{r}
var(earnings_clean$height)*(length(earnings_clean$height)-1)/length(earnings_clean$height)*1374
mean(earnings_clean$height)

se_linpred2 = median(sigma2)*sqrt((1/1374) + ((65 - 66.596)^2)/19860.82)
fround(se_linpred2, 2)
```


$\textbf{8.8.6 (b)}$
(repeating the exercise with the prediction functions)
```{r}
new2 <- data.frame(height=65)

linpred2 <- posterior_linpred(m3, newdata = new2)

pred_value2 <- posterior_predict(m3, newdata = new2)

median(linpred2)
mad(linpred2)

median(pred_value2)
mad(pred_value2)
```
\textbf{Shadow topic:}


```{r}
hist(y_pred)
plot(a2,b2)
```

Compared to using the deafualt weakly informative priors, using a combination of a (hopefully) informative prior for the coefficient with a default (weakly informative) prior for the intercept here yields a plot of simulation draws (a, b) looking more like the plots from the textbook - i.e., with what would be more distinctive principal components and pairs clearly more concentrated around the means of the respective parameters

```{r}
median(a2)
median(b2)
```

$\textbf{8.8.7}$

Stimulating fake data according to the experiment conducted 

```{r}
library(rstanarm)
n = 100
x_values = abs(rnorm(n, 20, 20)) #getting absolute values because there's no negative minutes
a = rnorm(n, 0, 5000) #intercept. This presupposes that the estimated revenue with 0 minute of ad showing. It is centered at 0. The standard deviation implies that this value can be negative( Not showing ads may negatively impact revenues) or positive (the product is well known and can generate revenue without ads). 

b = rnorm(n, 500000, 200000) #estimated revenue by min of ad display. It's centered at 500K with a std of 200K as per the experiment. 

sigma = 50000 # assuming a standard error of 10% of the estimated slope: 50000 

#constructing the equation for y 
y = a + b*x_values + sigma * abs(rnorm(n, 20, 20))

#making a dataframe of fake data
fake = data.frame(x_values,y)
```

Below, the stan_glm model is fit on the fake dataset. As instructed, the slope estimate prior is set at 500,000, and the estimate standard deviation is at 200,000. 
```{r}
M1 = stan_glm(y ~ x_values , data = fake,
              prior = normal(500000, 200000, autoscale = FALSE))

print(M1)
```


Given the above model, we can predict how much revenue is expected to be generated at a 20 minute ad showing. 

```{r}
new = data.frame(x_values=20)
y_pred1 = posterior_predict(M1, newdata = new)

x = 20
cost_per_min = 300000

expected_net_gain = median(y_pred1)
std_net_gain = mad(y_pred1)
loss_prob = mean(y_pred1 < cost_per_min * x) 

print(c("Expected Net Gain",expected_net_gain))
print(c("Std Net Gain",std_net_gain))
print(c("Probability of Negative Net Gain",loss_prob)) 

```

\textbf{SHADOW TOPIC:}

The use of simulations to generate data inspired by the reports of an experiment is interesing - especially in the context of later using these data in bayesian inference, where one is specifying prior distributions of parameteres, presumably either in line with how they were generated or with an intentional departure from what one assumes the experimenter had available but is not akin to the general case. 





